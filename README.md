# Two Phase Heuristic Method to Solve CVRP in Spark

## Requirements
MapReduce programming model is used to design the algorithm, which allows
us to perform parallel processing across Big Data using a large number of
nodes (multiple computers).
Apache spark is used in Python3 to implement the MapReduce framework of
the algorithm. The following are required to run the algorithm:
* Apache Spark
* Java Development Kit(JDK)
* SBT
* Scala
* Python3
